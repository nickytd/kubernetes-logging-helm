# Default values for kubernetes-logging.
# Global values
cluster_name: "logging"
imagePullSecrets: []
priority_class: "logging"
storage_class: "standard"

#ES configuration
#A complete ES setup is provisioned when "in_cluster" is set to true. It can be scaled accordingly to the environment needs
#with the concrete configurations of the nodes that follow.
#In case "in_cluster" is set to false, logs are pushed to an external ES.
elasticsearch:
  single_node: false
  in_cluster: true
  snapshot:
    enabled: false
    storage_class: ""
    size: "5Gi"
  retention_days: 7
  additional_jvm_params: "-Djava.net.preferIPv4Stack=true -XshowSettings:properties -XshowSettings:vm -XshowSettings:system"
  url: ""
  port: 9200
  user: "esadmin"
  password: "esadmin"

#Opendistro configuration 
opendistro:
  image: "amazon/opendistro-for-elasticsearch"
  imageTag: 1.13.2
  saml:
    enabled: false
    idp: {}
      #metadata_url:
      #entity_id:
    sp: {}
      #entity_id:
    exchange_key: ""
    admin_role: ""
    viewer_role: ""
    tenant_role: ""

#ES Curator job configuration
es_curator:
  image: "nickytd/es-curator"
  imageTag: "5.8"

#Init container configuration. Used for multiple application startup checks
init_container:
  image: "nickytd/init-container"
  imageTag: "0.1.0"
  imagePullPolicy: IfNotPresent

#Configuration of ES master node if "in_cluster" is true
master:  
  replicas: 1
  storage: "1Gi"
  heap_size: "256m"
  resources:
    requests:
      memory: "600Mi"
    limits:
      memory: "600Mi"
  storage_class: ""
  priority_class: ""
  tolerations: []
  affinity: {}    

#Configuration of ES coordination node if "in_cluster" is true
client:
  replicas: 1
  heap_size: "512m"
  resources:
    requests:
      memory: "1000Mi"
    limits:
      memory: "2000Mi"
  ingress:
    path: "/"
    enabled: false
    annotations: {}      
    tls: {}  
  tolerations: []
  affinity: {}
  topologySpreadConstraints: {}
  #- maxSkew: 1
  #  topologyKey: kubernetes.io/hostname
  #  whenUnsatisfiable: ScheduleAnyway
  #  labelSelector:
  #    matchLabels:
  #      type: client
  priority_class: ""

#Configuration of ES data node if "in_cluster" is true
data:
  replicas: 1
  heap_size: "512m"
  storage: "1Gi"
  resources:
    requests:
      memory: "1000Mi"
    limits:
      memory: "2000Mi"
  storage_class: ""
  priority_class: ""    
  tolerations: []
  affinity: {} 

#when in_cluster is set to false it determines an external kibana instance. 
#In this case only jobs creating index templates and kibana objects are executed.
kibana:
  in_cluster: true
  url: ""  
  replicas: 1
  extraEnvs:
  - name: "NODE_OPTIONS"
    value: "--max-old-space-size=350"
  user: "kibana"
  password: "kibana"
  readonly:
    user: "viewer"
    password: "view"
  developer:
    user: "developer"
    password: "develop"   
  ingress:
    path: "/"
    enabled: false
    annotations: {}
    tls: {}  
  index_patterns:
    - containers
    - nginx
    - systemd    
  tenants:
    - Global
    - Developer
  resources:
    requests:
      memory: "500Mi"
    limits:
      memory: "500Mi"
  tolerations: []
  affinity: {}
  priority_class: "" 

fluentbit:
  image: "fluent/fluent-bit"
  imageTag: "1.8.1"
  host_path: /var/log
  resources:
    requests:
      memory: "50Mi"
    limits:
      memory: "100Mi"
  priority_class: ""
  tolerations: []
  affinity: {}
  metrics:
    enabled: false
    interval: "30s"
    namespace: ""

fluentd:
  replicas: 1
  image: "fluent/fluentd-kubernetes-daemonset"
  imageTag: "v1.12-debian-kafka-1"
  resources:
    requests:
      memory: "100Mi"
    limits:
      memory: "500Mi"  
  priority_class: ""
  tolerations: []
  affinity: {}
  topologySpreadConstraints: {}
  #- maxSkew: 1
  #  topologyKey: kubernetes.io/hostname
  #  whenUnsatisfiable: ScheduleAnyway
  #  labelSelector:
  #    matchLabels:
  #      k8s-app: fluentd


#In scaled out setup kafka queues are used as ingestion points to accommodate spiked in the logging stream volumes
kafka:
  enabled: true
  replicas: 1
  image: "wurstmeister/kafka"
  imageTag: "2.13-2.7.0"
  heap_size: "256m"
  storage: "1Gi"
  topics:
    config: "retention.bytes=134217728,retention.ms=3600000,message.timestamp.difference.max.ms=3600000,message.timestamp.type=LogAppendTime"
    name: ["containers"]    
  resources:
    requests:
      memory: "600Mi"
    limits:
      memory: "600Mi"
  storage_class: ""
  priority_class: ""
  tolerations: []
  affinity: {}   

#Zookeeper is a dependency of kafka
zookeeper:
  replicas: 1
  image: "zookeeper"
  imageTag: "3.7.0"
  heap_size: "128m"
  storage: 1Gi
  resources:
    requests:
      memory: "300Mi"
    limits:
      memory: "300Mi"
  storage_class: ""
  priority_class: ""
  tolerations: []
  affinity: {}